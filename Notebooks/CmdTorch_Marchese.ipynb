{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "782fc82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *\n",
    "from cmd_classes_funcs_Marchese import MyModel, ImageWithCmdDataset, get_class_labels, get_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec812a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes and filenames\n",
    "path = Path(\"data\")\n",
    "classes = get_class_labels(path)\n",
    "all_filenames = get_filenames(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e683d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset\n",
    "dataset = ImageWithCmdDataset(classes, all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80186b5",
   "metadata": {},
   "source": [
    "## Splitting Data into train/validate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6329781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting size of dataset and corresponding list of indices\n",
    "dataset_size = len(dataset.all_filenames)\n",
    "dataset_indices = list(range(dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5946f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the indices\n",
    "np.random.shuffle(dataset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "792b1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting index for where we want to split the data\n",
    "val_split_index = int(np.floor(0.2 * dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44c842e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting list of indices into training and validation indices\n",
    "train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b219033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a0a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset, shuffle=False, batch_size=16, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset=dataset, shuffle=False, batch_size=16, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2808ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate MyModel class\n",
    "net = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bf101ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr =0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bb5053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc0ba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0/50:734407.6653251648\n",
      "Training loss at epoch 1/50:38626.86206626892\n",
      "Training loss at epoch 2/50:28604.067169189453\n",
      "Training loss at epoch 3/50:10575.522519011425\n",
      "Training loss at epoch 4/50:5100.560373734683\n",
      "Training loss at epoch 5/50:2962.457620885671\n",
      "Training loss at epoch 6/50:2171.4828407882014\n",
      "Training loss at epoch 7/50:2387.4256314779973\n",
      "Training loss at epoch 8/50:1190.645436181659\n",
      "Training loss at epoch 9/50:930.0566432487838\n",
      "Training loss at epoch 10/50:850.0747101508053\n",
      "Training loss at epoch 11/50:1224.7386995327033\n",
      "Training loss at epoch 12/50:1535.0129023486907\n",
      "Training loss at epoch 13/50:657.9374317722884\n",
      "Training loss at epoch 14/50:290.05102610344227\n",
      "Training loss at epoch 15/50:185.96324007109365\n",
      "Training loss at epoch 16/50:146.19248726676915\n",
      "Training loss at epoch 17/50:126.93180081435446\n",
      "Training loss at epoch 18/50:119.2474887117396\n",
      "Training loss at epoch 19/50:96.96433655175849\n",
      "Training loss at epoch 20/50:81.12622258849728\n",
      "Training loss at epoch 21/50:70.18190080897307\n",
      "Training loss at epoch 22/50:64.11858418095471\n",
      "Training loss at epoch 23/50:59.57781326080783\n",
      "Training loss at epoch 24/50:67.61007222591434\n",
      "Training loss at epoch 25/50:52.24144615190198\n",
      "Training loss at epoch 26/50:47.519878627703974\n",
      "Training loss at epoch 27/50:46.583253143829324\n",
      "Training loss at epoch 28/50:41.812729433546565\n",
      "Training loss at epoch 29/50:38.342777922523055\n",
      "Training loss at epoch 30/50:36.408734443471076\n",
      "Training loss at epoch 31/50:35.02008174877085\n",
      "Training loss at epoch 32/50:35.02218235870225\n",
      "Training loss at epoch 33/50:37.279318823155904\n",
      "Training loss at epoch 34/50:36.902623370666234\n",
      "Training loss at epoch 35/50:41.93744332605392\n",
      "Training loss at epoch 36/50:31.198651713484082\n",
      "Training loss at epoch 37/50:42.37346944216556\n",
      "Training loss at epoch 38/50:40.054524905156285\n",
      "Training loss at epoch 39/50:34.90105678780587\n",
      "Training loss at epoch 40/50:28.23234444050715\n",
      "Training loss at epoch 41/50:35.4995885401795\n",
      "Training loss at epoch 42/50:51.08674608172049\n",
      "Training loss at epoch 43/50:46.717901157982105\n",
      "Training loss at epoch 44/50:25.62651102859678\n",
      "Training loss at epoch 45/50:27.566309786128137\n",
      "Training loss at epoch 46/50:26.31677370185878\n",
      "Training loss at epoch 47/50:22.254651605558248\n",
      "Training loss at epoch 48/50:23.57862682436587\n",
      "Training loss at epoch 49/50:18.585784486067112\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Model training\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        # get the inputs\n",
    "        inp_data, label = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = net(inp_data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Training loss at epoch {epoch}/{num_epochs}:\" + str(running_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "deb3975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 897/1135 = 79.03%\n"
     ]
    }
   ],
   "source": [
    "# Checking accuracy on valisation set\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in val_loader:\n",
    "\n",
    "        inp_data, label = data\n",
    "\n",
    "        # predict\n",
    "        output = net(inp_data)\n",
    "        \n",
    "        # Checking if there are multiple batches\n",
    "        if output.size()[0] > 1:\n",
    "            \n",
    "            # For-loop accounts for multiple batches\n",
    "            for i in range(output.size()[0]):\n",
    "                \n",
    "                # Getting the probability of the predicted most probable move\n",
    "                prob = torch.max(output[i])\n",
    "                move = int()\n",
    "                \n",
    "                # Looking at what move has that probability\n",
    "                if prob == output[i][0]:\n",
    "                    move = 0\n",
    "                elif move == output[i][1]:\n",
    "                    move = 1\n",
    "                else:\n",
    "                    move = 2\n",
    "                \n",
    "                # Checking if the predicted move is the same as the label\n",
    "                if move == label[i]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "                \n",
    "        else:\n",
    "            # Getting the probability of the predicted most probable move\n",
    "            prob = torch.max(output)\n",
    "            move = int()\n",
    "            \n",
    "            # Looking at what move has that probability\n",
    "            if prob == output[0]:\n",
    "                move = 0\n",
    "            elif move == output[1]:\n",
    "                move = 1\n",
    "            else:\n",
    "                move = 2\n",
    "                \n",
    "            # Checking if the predicted move is the same as the label\n",
    "            if move == label:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "            \n",
    "        \n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on validation set: {correct}/{total} = {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f369beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'cmd_torch.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf59388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
