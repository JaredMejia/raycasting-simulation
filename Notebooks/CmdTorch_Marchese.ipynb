{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "782fc82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CAMPUS/cemb2020/anaconda3/envs/arcslab/lib/python3.8/site-packages/fastbook/__init__.py:18: UserWarning: Missing `graphviz` - please run `conda install fastbook`\n",
      "  except ModuleNotFoundError: warn(\"Missing `graphviz` - please run `conda install fastbook`\")\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333d638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageWithCmdDataset(Dataset):\n",
    "    def __init__(self, img_dir: Path):\n",
    "\n",
    "        # Creates labels for dataset: [\"left\", \"right\", \"straight\"]\n",
    "        # Does this through iterating through the directories in img_dir\n",
    "        # and splitting on the backslash in the path name (as d is data/<label>),\n",
    "        # then taking the last item of the list produced by .split\n",
    "        self.class_labels = [str(d).split(\"/\")[-1] for d in img_dir.iterdir() if d.is_dir() and \".ipynb_checkpoints\" not in str(d)]\n",
    "        self.class_indices = {lbl:i for i, lbl in enumerate(self.class_labels)}\n",
    "        \n",
    "        # Get all filenames\n",
    "        self.all_filenames = []\n",
    "        for d in img_dir.iterdir():\n",
    "            if d.is_dir():\n",
    "                self.all_filenames += [item for item in d.iterdir() if \".ipynb_checkpoints\" not in str(item)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # img_filename looks like data/<label>/<number>-<previous_move>.png\n",
    "        img_filename = self.all_filenames[index]\n",
    "        \n",
    "        # Opens image file and converts it into a tensor\n",
    "        img = Image.open(img_filename)\n",
    "        img = img.resize((128,128))\n",
    "        img = torch.Tensor(np.array(img)/255)\n",
    "        img = img.permute(2,0,1)\n",
    "        \n",
    "        # Replaces - and . with spaces then splits on the spaces\n",
    "        # taking the item at index 1 which is the <previous_move>\n",
    "        cmd_name = img_filename.name.replace(\"-\", \" \").replace(\".\", \" \").split()[1]\n",
    "        cmd = self.class_indices[cmd_name]\n",
    "        \n",
    "        # img_filename.parent takes the parent directory of img_filename\n",
    "        # then that is made to be of type string, split on the backslashes\n",
    "        # and the <label> in img_filename is taken\n",
    "        label_name = str(img_filename.parent).split(\"/\")[-1]\n",
    "        label = self.class_indices[label_name]\n",
    "        \n",
    "        # Data and the label associated with that data\n",
    "        return (img, cmd), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec812a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img: tensor([[[0.8392, 0.8471, 0.8431,  ..., 0.2745, 0.2275, 0.2510],\n",
      "         [0.8314, 0.8431, 0.8392,  ..., 0.2588, 0.2118, 0.2235],\n",
      "         [0.8392, 0.8353, 0.8353,  ..., 0.2353, 0.1843, 0.1765],\n",
      "         ...,\n",
      "         [0.1098, 0.2471, 0.3961,  ..., 0.2157, 0.2196, 0.2078],\n",
      "         [0.6000, 0.6078, 0.5961,  ..., 0.2431, 0.2471, 0.2706],\n",
      "         [0.5961, 0.6078, 0.5843,  ..., 0.1804, 0.1961, 0.1843]],\n",
      "\n",
      "        [[0.8196, 0.8235, 0.8235,  ..., 0.2745, 0.2275, 0.2510],\n",
      "         [0.8157, 0.8235, 0.8196,  ..., 0.2588, 0.2118, 0.2314],\n",
      "         [0.8235, 0.8196, 0.8157,  ..., 0.2353, 0.1843, 0.1804],\n",
      "         ...,\n",
      "         [0.1020, 0.2157, 0.3333,  ..., 0.2235, 0.2275, 0.2039],\n",
      "         [0.5137, 0.5216, 0.5098,  ..., 0.2353, 0.2510, 0.2902],\n",
      "         [0.5098, 0.5216, 0.4980,  ..., 0.1608, 0.1725, 0.1686]],\n",
      "\n",
      "        [[0.8078, 0.8078, 0.8157,  ..., 0.2745, 0.2235, 0.2510],\n",
      "         [0.8039, 0.8118, 0.8078,  ..., 0.2588, 0.2118, 0.2039],\n",
      "         [0.8118, 0.8118, 0.8039,  ..., 0.2314, 0.1490, 0.1451],\n",
      "         ...,\n",
      "         [0.0941, 0.1922, 0.2784,  ..., 0.2039, 0.2000, 0.2078],\n",
      "         [0.4431, 0.4549, 0.4353,  ..., 0.2078, 0.2078, 0.1961],\n",
      "         [0.4431, 0.4510, 0.4314,  ..., 0.1647, 0.1725, 0.1529]]])\n",
      "cmd: 0\n",
      "label: 0\n"
     ]
    }
   ],
   "source": [
    "dataset = ImageWithCmdDataset(Path(\"data\"))\n",
    "#print(dataset.class_labels)\n",
    "#print(dataset.all_filenames)\n",
    "\n",
    "(img, cmd), label = dataset[5]\n",
    "\n",
    "print(f\"img: {img}\")\n",
    "print(f\"cmd: {cmd}\")\n",
    "print(f\"label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80186b5",
   "metadata": {},
   "source": [
    "## Splitting Data into train/validate sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6329781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting size of dataset and corresponding list of indices\n",
    "dataset_size = len(dataset.all_filenames)\n",
    "dataset_indices = list(range(dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5946f9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the indices\n",
    "np.random.shuffle(dataset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "792b1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting index for where we want to split the data\n",
    "val_split_index = int(np.floor(0.2 * dataset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c842e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting list of indices into training and validation indices\n",
    "train_idx, val_idx = dataset_indices[val_split_index:], dataset_indices[:val_split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b219033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating samplers\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a0a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset, shuffle=False, batch_size=16, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset=dataset, shuffle=False, batch_size=16, sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "484f6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.cnn.fc.out_features + 1, 512)\n",
    "        self.fc2 = nn.Linear(512, 3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        img, cmd = data\n",
    "        x1 = self.cnn(img)\n",
    "        x2 = cmd.unsqueeze(1)\n",
    "        \n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2808ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bf101ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb5053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc0ba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at epoch 0/50:87.34523776437165\n",
      "Training loss at epoch 1/50:361.00409464467407\n",
      "Training loss at epoch 2/50:403.5047588678369\n",
      "Training loss at epoch 3/50:137.84290138223878\n",
      "Training loss at epoch 4/50:127.12608030765114\n",
      "Training loss at epoch 5/50:119.786013425095\n",
      "Training loss at epoch 6/50:120.00354105234146\n",
      "Training loss at epoch 7/50:73.3855157494545\n",
      "Training loss at epoch 8/50:71.54979711771011\n",
      "Training loss at epoch 9/50:70.07654637098312\n",
      "Training loss at epoch 10/50:68.7849685549736\n",
      "Training loss at epoch 11/50:67.64779061079025\n",
      "Training loss at epoch 12/50:66.64379113912582\n",
      "Training loss at epoch 13/50:65.7557423710823\n",
      "Training loss at epoch 14/50:64.96927785873413\n",
      "Training loss at epoch 15/50:64.27215683460236\n",
      "Training loss at epoch 16/50:63.65384244918823\n",
      "Training loss at epoch 17/50:63.10516554117203\n",
      "Training loss at epoch 18/50:62.618098735809326\n",
      "Training loss at epoch 19/50:62.185601234436035\n",
      "Training loss at epoch 20/50:61.801456570625305\n",
      "Training loss at epoch 21/50:61.460186779499054\n",
      "Training loss at epoch 22/50:61.15694522857666\n",
      "Training loss at epoch 23/50:60.887444853782654\n",
      "Training loss at epoch 24/50:60.647883892059326\n",
      "Training loss at epoch 25/50:60.43490815162659\n",
      "Training loss at epoch 26/50:60.245530903339386\n",
      "Training loss at epoch 27/50:60.07711613178253\n",
      "Training loss at epoch 28/50:59.92731446027756\n",
      "Training loss at epoch 29/50:59.79405578970909\n",
      "Training loss at epoch 30/50:59.675488501787186\n",
      "Training loss at epoch 31/50:59.569982290267944\n",
      "Training loss at epoch 32/50:59.47608178853989\n",
      "Training loss at epoch 33/50:59.392514139413834\n",
      "Training loss at epoch 34/50:59.31811934709549\n",
      "Training loss at epoch 35/50:59.2518875002861\n",
      "Training loss at epoch 36/50:59.19292050600052\n",
      "Training loss at epoch 37/50:59.14041230082512\n",
      "Training loss at epoch 38/50:59.09365141391754\n",
      "Training loss at epoch 39/50:59.052013635635376\n",
      "Training loss at epoch 40/50:59.01493087410927\n",
      "Training loss at epoch 41/50:58.98189887404442\n",
      "Training loss at epoch 42/50:58.95248460769653\n",
      "Training loss at epoch 43/50:58.92627528309822\n",
      "Training loss at epoch 44/50:58.90294051170349\n",
      "Training loss at epoch 45/50:58.88215947151184\n",
      "Training loss at epoch 46/50:58.86364686489105\n",
      "Training loss at epoch 47/50:58.8471559882164\n",
      "Training loss at epoch 48/50:58.832478016614914\n",
      "Training loss at epoch 49/50:58.819404661655426\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        # get the inputs\n",
    "        inp_data, label = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        output = net(inp_data)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f\"Training loss at epoch {epoch}/{num_epochs}:\" + str(running_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "deb3975e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 211/1135 = 18.59%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for data in val_loader:\n",
    "\n",
    "        inp_data, label = data\n",
    "\n",
    "        # predict\n",
    "        output = net(inp_data)\n",
    "        \n",
    "        # For-loop accounts for multiple batches\n",
    "        if output.size()[0] > 1:\n",
    "            for i in range(output.size()[0]):\n",
    "                if round(float(torch.max(output[i]))) == label[i]:\n",
    "                    correct +=1\n",
    "                total +=1\n",
    "        else:\n",
    "            if round(float(torch.max(output))) == label:\n",
    "                correct +=1\n",
    "            total +=1\n",
    "            \n",
    "        \n",
    "accuracy = correct / total\n",
    "print(f\"Accuracy on validation set: {correct}/{total} = {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f369beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'cmd_torch.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf59388",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
